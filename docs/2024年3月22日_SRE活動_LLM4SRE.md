## 時間

- 3/22 20:00-20:10(10m)
- 3/23 13:00-13:30(30m)
- 3/23 16:00-16:42(42m)

## やること

- LLM for SRE“の世界探索 を読む https://blog.yuuk.io/entry/2024/the-world-of-llm4sre

## 次のアクション

- 最新の情報を得るための旅に出る
  - 障害スナップショットについて
        既存論文は、テレメトリデータに対するクエリを自動生成することと、テレメトリデータのフィルタリングなどのテクニックを採用
            Xpertはテレメトリデータに対するクエリのDSL（Domain Specific Language）をLLMにより生成する
            Pandaはメトリクスの時系列データに対して、変化点検知により変化点のなかったメトリクスを除去し、障害に関連するデータを絞り込んでいる
  - ダイジェスト化について
        コンテキストウィンドウの使用量を低減するために、テレメトリデータの頭部のみを表示し、ハッシュIDを残す。
            その後、必要に応じて長文テキストを直接パラメータとして扱うのではなく、
            ハッシュIDからデータ本体を参照するようにLLMに指示する
  - テレメトリの障害スナップショットとダイジェスト化技術の標準的な手法や実装が課題
        ObservabilityのコミュニティOpenTelemetryにより標準化が進んでいるが、テレメトリの障害スナップショットとダイジェスト化技術の標準的な手法や実装が課題
- LLMの診断結果の説明性
  - LLMエージェントを採用した障害診断法では、なぜLLMがそのような診断をしたのかを根拠を提示する研究や製品UIが必要となるはず
- 人間との協働
  - 人間のSREsからのLLMエージェントへのフィードバック
    - 単純なフィードバック機構を搭載
  - 人間のSREsをLLMエージェントのワークフローに介入させるアプローチ
    - AIソフトウェアエンジニアDevinの場合
      - ソフトウェア開発のための自律エージェントDevinでは認証が必要な操作は人間のソフトウェアエンジニアに介入させるようになっている
- プロセスデータの管理
  - LLMエージェントは、人間のエンジニアのヒントなしに、高レベルの診断プロセスを導くことは困難
   - 手動による診断プロセスをいかに管理するが重要

## 備忘録


- LLMは、SREやAIOpsの研究開発にはあまり関係ない? 理由は自然言語ではなく数値のデータを解析することが求められるから。
  - AIOpsでは典型的にはいわゆるObservabilityデータ（メトリクス、ログ、トレースなど）が入力となる
    - 自然言語ではなく数値のデータを解析することが求められる
      - AIOpsとChatGPTに強い関係性は見いだせなかった
        - 自然言語のタスクを研究対象としていなかったため?
- 一方、SREのためのLLM（LLM for SRE, LLM4SRE）に関する論文も存在する。優れた推論機械としての性質に注目している。
  - SREの障害診断は、人間の専門家が推論と、ツールを介したデータ取得とシステム操作を反復する試行錯誤のプロセスである
    - 熟練のエンジニアが障害に対応する際に、事前にもつ知識とその場の調査内容を基に推論を重ねて原因を特定する様を連想する
    - 実世界に展開可能となるまでにはまだ時間がかかるだろう
  - 実世界のデータの検索器とシステム操作のためのツールによりLLMを拡張。熟練のエンジニアの障害対応を模して、反復的な推論や複数のLLMの協調を実現した。
    - RCAgent
    - D-Bot
  - ITシステムの障害診断をLLMにより自動化する手法に関する最新の研究動向を俯瞰して探索
    - 2022年11月のChatGPTのローンチ後に次々とLLM4SREの障害管理をテーマとする論文が発表されている
      - クラウド上に展開されるシステムに発生する障害診断をLLMにより自動化するアプローチが研究されている
        - SRE固有の一般的なドメイン知識を検索したり、
        - ローカルのシステムが保持するデータ（過去のインシデント、テレメトリなど）をLLMのプロンプトに注入する
      - SRE = オンラインサービスのテレメトリデータ（メトリクス、ログ、トレース、イベントなど）やインシデントデータ（アラート、チケット、ポストモーテムのテキストなど）を機械学習、統計、データマイニングの技術により解析し、障害管理（Failure Management）を自動化する研究が盛ん
        - 国内カンファレンスSRE NEXT 2022
        - これらの研究で提案されているほとんどの手法は、時系列データなどの多変量データの数値解析に基づき、障害検知、障害原因特定、障害緩和などのタスクを実行するもの

      - MicrosoftやAWS、Alibabaといった大手事業者の研究グループが発表した論文でさえ、英語圏も含めたSNS上でほとんど注目されていない

- LLM4SREの障害診断技術を提案する論文を複数の異なる区分で分類
  - 分類
    - 1) ファインチューニングベース
      - 2022年11月にMicrosoft ResearchからLLM4SREでは初の研究[Ahmed+,ICSE'23]が公開された。
      - Microsoftの40,000件以上のインシデントのタイトルやサマリーなどのテキストデータを用いて、GPT-3.5をファインチューニングしている。
      - 2023年5月公開のOasisは、個別具体的なシステムのドメイン用語を理解させるために、同じくGPT-3.5をファインチューニングすることにより、障害状況の要約文を自動で作成する。
    - 2) 検索拡張言語ベース
      - [Zhang+,2024]は、現在アクティブな障害に類似する過去の障害の文書を履歴から検索し、LLMのプロンプトにFew-Shotとして例示することで、アクティブな障害の説明テキストを入力として根本原因を予測させる。
      - PACE-LMは障害履歴を基に予測させた根本原因がどの程度信頼できるかをキャリブレーションし、信頼度スコアを付与する。過去ではなく、今何が起きているか？を示すテレメトリデータも検索するアプローチとして、RCACopilotとPandaがある。
    - 3) LLMエージェントベース
      - より発展的なアプローチとして、[Roy+,2024]、RCAgent、D-BotなどのLLMエージェントに基づく研究がある。
      - エージェントベースのアプローチは、検索拡張に加えてツール拡張を備え、検索とツールの実行と推論を折り重ねることで、まるで人間のエンジニアが試行錯誤するかのように、障害原因を自律的に診断する。
  - 特徴
      - 対象システム
        - クラウド / アプリケーション
        - メールサービス
        - マイクロサービス
        - ネットワーク
        - データベース
      - ドメイン固有データとツール
        - インシデントの履歴。タイトルとサマリーのみ。
        - インシデントの履歴。手動作成の要約を含む。
        - インシデントの履歴
        - インシデント履歴（メタデータ、タイトル、概要、ディスカッション）、クエリ履歴
        - インシデント履歴と詳細、Runbook相当の文書
        - アラート、トポロジー、ログ、メトリクス（Golden Signal）
        - テレメトリ（メトリクス/ログ）、インシデント履歴
        - 非構造化データ（ログ/コード）
        - データベース製品文書、pg_stat_statements、
        - Auroraのwaitイベント文書と250のDBメトリクス
      - LLM技術
        - Instruction Tuning
        - Few-Shot, RAG
        - Few-Shot
        - Few-Shot, Instruction Tuning
        - RAG
        - LLMエージェント
        - LLMエージェント, マルチエージェント
      - 使用する主なモデル
        - GPT-3 / GPT-3.5
        - GPT-3.5
        - GPT-3.5 / GPT-4
        - GPT-4
        - ChatGPT / Flan T5 XXL
        - Vicuna
      - タスク
        - 障害の要約テキストの生成
        - 関連する複数のインシデントの要約テキストの生成
        - 根本原因と緩和策の予測
        - 根本原因の予測
        - 根本原因カテゴリの予測
        - 予測された根本原因の信頼性スコアの計算
        - 症状、根本原因、緩和策を含む診断レポートの生成
        - 緩和計画の生成
        - 障害の修復のためのコード生成
        - テレメトリデータ分析用ドメイン固有言語の生成

```
[Ahmed+, ICSE'23]	クラウド	根本原因と緩和策の予測	インシデントの履歴。タイトルとサマリーのみ。	Instruction Tuning	GPT-3.5	
[Jin+, FSE'23] (Oasis)	クラウド	関連する複数のインシデントの要約テキストの生成	インシデントの履歴。手動作成の要約を含む。	Instruction Tuning	GPT-3 / GPT-3.5	
[Zhang+, 2024]	クラウド	根本原因の予測	インシデントの履歴	RAG + Few-Shot	GPT-4	
[Zhang+,2023] (PACE-LM)	クラウド	予測された根本原因の信頼性スコアの計算	インシデントの履歴	RAG + Few-Shot	GPT-4	
[Samanta+, CLOUD'23] (InsightsSumm)	クラウド /
アプリケーション	障害の要約テキストの生成	アラート、トポロジー、ログ、メトリクス（Golden Signal）	Few-Shot	ChatGPT / Flan T5 XXL	
[Chen+, EuroSys'24] (RCACopilot)	メールサービス	根本原因カテゴリの予測	テレメトリ（メトリクス/ログ）、インシデント履歴	RAG + Few-Shot	GPT-4	
[Komal+, CASCON'23] (ADARMA)	マイクロサービス	障害の修復のためのコード生成	テレメトリ（メトリクス/ログ）、公開Runbook	Few-Shot, Instruction Tuning	NA	
[Roy+,2024]	クラウド	根本原因の予測	インシデント履歴と詳細、Runbook相当の文書	LLMエージェント（ReAct）	GPT-4	
[Wang+,2023] (RCAgent)	クラウド	根本原因の予測	非構造化データ（ログ/コード）	Zero-Shot CoT, LLMエージェント（ReActの拡張）, Self-Consistency	Vicuna	
[Hamadanian+,HotNets'23]	ネットワーク	緩和計画の生成	インシデントの情報とメタデータ（詳細不明）	LLMエージェント	NA	
[Zhou+, 2023] (D-Bot)	データベース	症状、根本原因、緩和策を含む診断レポートの生成	データベース製品文書、pg_stat_statements、	LLMエージェント, マルチエージェント	GPT-4	
[Singh+,2024] (Panda)	データベース	症状、根本原因、緩和策を含む診断レポートの生成	Auroraのwaitイベント文書と250のDBメトリクス	RAG	GPT-4	
[Jiang+, ICSE'24] (Xpert)	クラウド	テレメトリデータ分析用ドメイン固有言語の生成	インシデント履歴（メタデータ、タイトル、概要、ディスカッション）、クエリ履歴	Few-Shot + RAG	GPT-3.5 / GPT-4
```

- 今後の方向性

```
スナップショットとダイジェスト化
    RCACopilot、RCAgent、D-Bot、および、Pandaなどは、障害発生時にローカルのシステムのテレメトリデータをLLMのプロンプトに取り込んでいる（障害スナップショットとここでは呼ぶ）
        RCACopilotの論文で指摘されているように、余分な情報がプロンプトに含まれるとノイズとなり、精度が低下する
        LLMのコンテキストウィンドウの上限が増加しているとはいえ、現在発生中の障害に無関係の情報を削減しダイジェスト化できるかが重要

            障害スナップショットについて
                既存論文は、テレメトリデータに対するクエリを自動生成することと、テレメトリデータのフィルタリングなどのテクニックを採用
                    Xpertはテレメトリデータに対するクエリのDSL（Domain Specific Language）をLLMにより生成する
                    Pandaはメトリクスの時系列データに対して、変化点検知により変化点のなかったメトリクスを除去し、障害に関連するデータを絞り込んでいる
            ダイジェスト化について
                RCACopilotはログメッセージを含む不要な診断用情報を削減するために、診断用情報を約120〜140語以下に一旦要約している。
                RCAgentは、コンテキストウィンドウの使用量を低減するために、テレメトリデータの頭部のみを表示し、ハッシュIDを残す。
                    その後、必要に応じて長文テキストを直接パラメータとして扱うのではなく、
                    ハッシュIDからデータ本体を参照するようにLLMに指示する。
                    ツールのAPIは、エンティティIDのような単純なパラメータしか受け付けないようにする
            Observabilityのコミュニティ
                テレメトリの計装と保存についてはOpenTelemetryにより標準化が進んでいる。
                テレメトリの障害スナップショットとダイジェスト化技術は、標準的な手法や実装が未だ確立されていない。
                そのため、今後の研究、あるいは、実装の課題となる。
プロセスデータの管理
    RCACopilotと[Roy+,2024]は共通してトラブルシューティングのプロセスに着目

        RCACopilotはエンジニアがアラート種別ごとにルールベースの自動対応プロセスを事前に設計している
        [Roy+,2024]は診断の計画（プロセス）を手動で記述したRunbookを用いてReActが高レベルの診断計画を構築する。
        インシデントレポート（ポストモーテム）には、通常、診断ステップを実行するためのオペレーション知識ではなく、診断ステップの結果のみが含まれている。
            LLMエージェントは、人間のエンジニアのヒントなしに、高レベルの診断プロセスを導くことは困難
                手動による診断プロセスをいかに管理するが重要
LLMの診断結果の説明性
    モデルの予測に対する説明性または解釈性（Explainability）が重要
        機械学習一般に、モデルの予測に対する説明性または解釈性（Explainability）が重要であるとされている。
    モデルの予測が何をもって説明性をもつとするか
        モデルの予測が何をもって説明性をもつとするかは多岐に渡る。
    LLMを用いないAIOpsでは
        モデルの予測結果を人間への説明性を高めるために自然言語で説明するというアプローチを取りにくかった。
    LLMエージェントを採用した障害診断法
        反復の過程の履歴が残るため、その履歴を要約して人間に提示することにより、説明性は高くなりやすい
            PACE-LMは原因の診断結果がどの程度信頼できるかのスコア付けを行っている
                なぜLLMがそのような診断をしたのかを根拠を提示する研究や製品UIが必要となるはず
        しかし、LLMエージェントを採用した障害診断法では、反復の過程の履歴が残るため、その履歴を要約して人間に提示することにより、説明性は高くなりやすい。
        PACE-LMは原因の診断結果がどの程度信頼できるかのスコア付けを行っている。
        今後もなぜLLMがそのような診断をしたのかを根拠を提示する研究や製品UIが必要となるはずだ。

人間との協働
    人間のSREsからのLLMエージェントへのフィードバック
        [Roy+,2024]に書かれているように、人間のSREsからのフィードバックにより精度を向上させていくアプローチ
        Human in the Loop（より良いモデルを効率的に学習するために人間を活用すること）
            LLMの診断結果に対してその良し悪しを人間がフィードバックし、次回から改善されるサイクルも重要
            Pandaは単純なフィードバック機構を搭載しており、Few Shotで事例を列挙する際の事例を選択するときにフィードバック結果を反映している
    人間のSREsをLLMエージェントのワークフローに介入させるアプローチ
        危険な操作や人間にとって容易な操作で、人間のSREsをエージェントのワークフローに介入させる
        AIソフトウェアエンジニアDevinの場合
            ソフトウェア開発のための自律エージェントDevinでは認証が必要な操作は人間のソフトウェアエンジニアに介入させるようになっている
                人間を介入させることによりエージェントが全てをこなせなくとも有用となるように設計されている。
                    もし、ワークフローを一貫してLLMエージェントに任せようとすると、どこか一つのステップで意図しない動作が発生すると、そのエージェントは使いものにならなくなってしまう
                    人間を介入させることによりエージェントが全てをこなせなくとも有用となるように設計されている。
```

### LLMを使用するために必要となる基本用語を整理

- ファインチューニング（Fine-Tuning）
  - 出力内容や形式を用途に応じて調整・制御
    - 目的
      - 事前学習済みモデルの未知タスクに対する性能を改善することを目的とする
    - 方法
      - 学習の方法は、指示文を入力し、それに対する理想的な出力文を正解とした教師あり学習
        - 教師あり学習データセット
          - 指示文
          - 正解（理想的な出力文）

  - OpenAI APIには、Instruction Tuning機能がある 
    - Fine-tuning - OpenAI API
      - GPT-4の中でも最近のモデルやその他のAPIベースのLLMは、ファインチューニングのためのAPIが必ずしも公開されているわけではない
        - gpt-3.5-turboやgpt-4(experimental)が対象
      - ファインチューニングを使用できないことがある

  - Instructution Tuning と呼ばれる

- プロンプティングと文脈内学習
  - Zero-Shot Prompting : 学習時に一切見たことのないタスクに対して、事前学習済みのLLMの汎用的な知識を活用して推論を行う方法である。例えば、根本原因診断タスクでは、現在発生中の障害の説明のみをプロンプトにコンテキストとして含めて、その障害の根本原因はなにか？とLLMに質問することを指す。Zero-Shot Prompting | Prompt Engineering Guide\
  - Few-Shot Prompting：少数の事例をプロンプトに含めることで、LLMにタスクの解き方を示唆し、性能を向上させる手法である。（“Language Models are Few-Shot Learners”, NeurIPS2020） Few-Shot Prompting | Prompt Engineering Guide
  - Chain-of-Thought Prompting（CoT、思考連鎖）: 単に最終的な答えを出すのではなく、Few-Shotの事例の際に、途中の思考の流れを明示することで、回答の質や説得力を高める。（“Chain of Thought Prompting Elicits Reasoning in Large Language Models”, NeurIPS2022） Chain-of-Thought Prompting | Prompt Engineering Guide\
  - Zero-Shot Chain-of-Thought：Few-Shotの事例なしで、単に"Let's think step by step."とプロンプトに指示を追加するだけでCoTを実現する手法である。（”Large Language Models are Zero-Shot Reasoners”, NeurIPS2022）Chain-of-Thought Prompting | Prompt Engineering Guide
  - Self Consistency（自己無矛盾性）: 複数のプロンプトや推論結果の整合性を評価し、最も無矛盾な結果を多数決で選択することで、LLMの出力の一貫性を高める手法である。CoTの推論能力を改善する。（“Self-Consistency Improves Chain of Thought Reasoning in Language Models”, ICLR2023）Self-Consistency | Prompt Engineering Guide\

- 拡張言語モデル（Augmented Language Model: ALM）
  - Retrieval Augmented Laguage Models（検索拡張言語モデル）
    - RAG（Retrieval Augmented Generation）
      - 検索した文書を元の入力に結合してコンテキストとして入力する手法をRAG（Retrieval Augmented Generation） と呼ぶ
        - LLMの推論時に、外部の知識源（Wikipediaや社内文書など）から関連する情報を検索し、言語モデルに提示する
      - 文書の検索には、外部テキストdからクエリqに類似した文書を見つけるための
      - 検索器（Retriever）
        - 文書の検索には、外部テキストdからクエリqに類似した文書を見つける役割を担う
          - 類似度の定義方法
            - 単語の出現頻度に基づくTF-IDF
            - テキストdとクエリqの各埋め込み（Embedding）ベクトル間のコサイン類似度

  - Tool Augmented Langage Models（ツール拡張言語モデル）
    - ReAct: Reasoning（推論）とAction（行動）を交互に繰り返すことで、LLMに複雑なタスクを自律的に遂行させるフレームワーク
      - 質問に答えるために必要な情報を外部ツールで検索したり、途中の計算結果を利用したりしながら、段階的に回答を構築する。
    - Reflexion: ReActフレームワークに自己評価、自己反省、記憶のコンポーネントを追加・拡張したもの https://www.promptingguide.ai/techniques/reflexion
      - LLMは過去の失敗から迅速かつ効果的に学習できる
    - ToolFormer: どのAPIを呼び出すか、いつ呼び出すか、どの引数を渡すか、そしてその結果をどのように将来のトークン予測に反映させるかを決定するために学習するモデルである。（“ToolFormer” Language Models Can Teach Themselves to Use Tools”, 2023）

# 2024年2月12日_生成AI

## 時間

- 2/12 20:00-22:12(2h12m)

## やること

- Vertex AI モデルガーデンの一覧を見て、次のアクションを考える

## 備忘録

### 言語
- 基盤モデル
    - Gemini Pro: The best performing Gemini model with features for a wide range of tasks. google/gemini-pro
        - 生成 AI, 言語
    - PaLM 2 Text Bison: Designed for single-turn instruction tasks like classification, extraction, summarization and generation. text-bison@002
        - 基盤,言語,表形式,ドキュメント
    - Claude 2.0 (Preview): Claude 2.0 is a leading LLM from Anthropic that enables a wide range of tasks with excellent performance. claude-2p0
        - 基盤,言語,表形式,ドキュメント
    - Claude Instant 1.2 (Preview): Claude Instant 1.2 is Anthropic's faster, lower-priced yet very capable LLM, great for quick text-based use cases. claude-instant-1p2
        - 基盤,言語
    - Llama 2: Fine-tune & deploy Meta's Llama 2 models on Vertex AI.

### 表形式

- 基盤モデル(事前トレーニング済みマルチタスク モデル)
    - Claude 2.0(Preview)
    - Claude Instant 1.2(Preview)
- ファインチューニング可能なモデル(カスタム ノートブックまたはパイプラインでさらにファインチューニングできるモデル)
    - AutoGluon https://github.com/autogluon/autogluon/tree/master/docs
        - 予測,表形式
        - train and deploy high-accuracy machine learning and deep learning models for tabular data.
### ドキュメント

- 基盤モデル(事前トレーニング済みマルチタスク モデル)
    - Claude 2.0(Preview)
    - Claude Instant 1.2(Preview)
- タスク固有のソリューション(これら事前構築済みモデルのほとんどはすぐにそのまま利用できます。また、多くは独自のデータを使用してカスタマイズできます)
    - Document AI OCR processor
        - 抽出,ドキュメント
            - Document OCR can identify and extract text from documents in over 200 printed languages and 50 handwritten languages.
    - Form Parser
        - 抽出, ドキュメント
            - extract key-value pairs, checkboxes, tables from documents in over 200+ languages

### マルチモーダル

- Gemini Pro Vision
    - Created from the ground up to be multimodal (text, images, videos) and to scale across a wide range of tasks, google/gemini-pro-vision

- LLaVA 1.5
    - LLaVA-1.5は、Llama2をベースに視覚エンコーダを組み合わせて作られ、画像の理解力が集約されています

### ビジョン

- 基盤モデル
    - Imagen for Image Generation and Editing
        - Use text prompts to generative novel images, edit existing ones, edit parts of an image with a mask and more.
    - Stable Diffusion v2.1
        - Latent text-to-image diffusion model 
            - taking as input a text prompt, and generates an image. stabilityai/stable-diffusion-2-1
    - Stable Diffusion v1-5
        - Latent text-to-image diffusion model 
            - capable of generating photo-realistic images given a text input. runwayml/stable-diffusion-v1-5
    - InstructPix2Pix
        - Given an input image and a text prompt that tells the model what to do, the instruct-pix2pix model follows the prompt to edit the image by generating a new one. timbrooks/instruct-pix2pix
    - Embeddings for Multimodal

- ファインチューニング可能なモデル
    - tfhub/EfficientNetV2: EfficientNet V2 are a family of image classification models, which achieve better parameter efficiency and faster training speed than prior arts. tensorflow-hub/efficientnetv2
        - 分類, ビジョン
    - tfvision/vit: The Vision Transformer (ViT) is a transformer-based architecture for image classification. tfvision/vit-s16
        - 検出, ビジョン
    - tfvision/SpineNet: SpineNet is an image object detection model generated using Neural Architecture Search. tfvision/spinenet49
        - 検出, ビジョン
    - tfvision/YOLO: YOLO algorithm is a one-stage object detection algorithm that can achieve real-time performance on a single GPU. tfvision/scaled-yolo
        - 分類,ビジョン
    - ResNet (with checkpoint): Image classification model as described in the paper "Deep Residual Learning for Image Recognition".

- タスク固有のソリューション
    - Occupancy analytics: Detect people and vehicles in a video or image, plus zone detection, dwell time, and more. google/occupancy-analytics-001
        - 検出, ビジョン
    - Person/vehicle detector: Detects and counts people and vehicles in video. People/vehicle detector.
        - 検出, ビジョン
    - Object detector: Identify and locate objects in video. Object detector
        - 検出, ビジョン
    - PPE detector: Identify people and personal protective equipment (PPE). PPE detector
        - 検出, ビジョン
    - Person blur: "Mask or blur a person's appearance in video. People blur"
        - 認知, ビジョン
    - Product recognizer: Identify products at the GTIN or UPC level. Product recognizer
        - 認知, ビジョン
    - Tag recognizer: Extract text in product and price tags. Tag recognizer
        - 分類, ビジョン
    - Content moderation (Vision): Content Moderator (Vision) detects objectionable or unwanted content across predefined content labels (e.g., adult, violence, spoof) or custom labels provided by the user. Content Moderation
        - 検出, ビジョン
    - Face detector (Vision API): Face detector is a prebuilt Vision API model that detects multiple faces in media (images, video) and provides bounding polygons for the face and other facial "landmarks" along with their corresponding confidence values. Face Detector
        - 検出, ビジョン
    - Text detector (Vision API): Text detector detects and extracts text from images. It uses optical character recognition (OCR) for an image to recognize text and convert it to machine coded text.

### 音声

- Chirp: https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/75?hl=ja&project=tutorial-vertex-ai-2024
    - 生成AI, 認知タスク
        - Chirp is available through the Cloud Speech-to-Text API
          - Turning audio containing speech into formatted text representation.
          - Captioning of videos for providing subtitles.
            - 動画の字幕生成
          - Content transcription for entity extraction, content classification

### 動画

- 基盤モデル
    - ImageBind: "Deploy Meta's ImageBind model on Vertex AI."
        - 基盤, 言語, ビジョン
- ファインチューニング可能なモデル 兼 タスク固有のソリューション
    - MoViNet Video Clip Classification: MoViNets (Mobile Video Networks) provide a family of efficient video classification models, supporting inference of streaming video and on mobile devices.
        - 分類, 動画
        - 事前トレーニング済みの動画分類モデルを実行して、特定の動画のアクティビティ（ダンス、水泳、サイクリングなど）を分類
        - MoViNets (Mobile Video Networks) family of efficient video classification models
    - MoViNet Video Action Recognition: MoViNets (Mobile Video Networks) provide a family of efficient video classification models. The classification model supports video action recognition tasks with proper data preparation and inference algorithms.
        - 検出, 動画
            - MoViNets (Mobile Video Networks) 
            - video action recognition tasks
                - with proper data preparation and inference algorithms.
- タスク固有のソリューション
    - Bytetrack Multi-Object Tracking: ByteTrack is a multi-object tracking model that detects, identifies, and tracks objects across video frames.
        - 追跡,ビジョン,動画
        - 映像の中の物体のBounding boxとIDを推定するタスク
      - MoViNet Video Action Recognition
        - 検出
        - 動画

## 考察

- モダリティ（形態・形式・様式）, ファインチューニング可能なモデル, タスク固有のソリューションは、便利だけど、それぞれの守備範囲が重複していて、扱いづらいなー
    - 生成AI, ビジョン、音声、ドキュメント、表形式、マルチモーダル、動画それぞれ１つずつ代表でモデル概要を理解する
        - Imagen https://cloud.google.com/vertex-ai/docs/generative-ai/image/overview
        - Llama 2 https://console.cloud.google.com/marketplace/product/meta/llama-2?hl=ja
        - AutoGluon https://github.com/autogluon/autogluon/tree/master/docs
            - AutoGluonについてもっと知りたい
                - AWS SageMakerで使えるみたいだけど、実際に何に使ってる?
                    - AutoGluon-Tabular はモデルチューニングにも使用できますが、その設計ではスタッキング法やアンサンブル法を使用すると優れた性能が得られるため、ハイパーパラメーターの最適化は不要とは?
                    - AutoGluon-Tabularはモデルを複数のレイヤーに積み重ねてレイヤーごとにトレーニングすることで成功しています。

        - Gemini Pro Vision https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/overview
            - https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling
        - Document AI OCR processor https://cloud.google.com/document-ai/docs/overview
    - 基盤モデルと特定タスク向けのソリューションはどちらが優秀?

    - これをどのように学んで、使っているのだろうか。
        - Claude, Llama 2, PaLM 2など、学習済みの基盤モデルを単独で使用する（ことに集中する）
            - 単に流行しているモデルを学習している?
            - もしくは、タスク固有のモデルを学習することは諦めている（集中と選択している）
        - Youtuberが動画編集のために字幕生成用のAIを選んで使用するように、自分の仕事に直結するモデルを集中して学んでいる
        - 複数のモデルを組み合わせる技術を身につけて、いくつかのAIモデルを応用している
          - LangChainでできること

- 生成AIワークフローの構成要素を読み解く(生成AIがどのようにレスポンスを返却しているか) https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview
  - Generative AI Studio
  - Behind the scenes
  - Model customization
    - Data prep
    - Tune
    - Evaluate
    - Deploy
    - Monitor

- FAQを読む https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/multimodal-faqs

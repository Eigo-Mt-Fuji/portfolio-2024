# 2024年1月3日 SRE活動

## 時間

12/29 10:00-12:00(2h) IaC本を読む, SREについて学ぶ方法を考える。手持ちのDevOps本（自宅にあるSRE本）は7年以上古いものであることに気づく。新しいKindle本を探し始める。紙媒体しかないことがわかる。翌日本屋へ行くことにした。
12/30 11:00-11:30(0.5h) 新宿紀伊國屋で本を探す。SRE実践本とPython本を購入することした。k8s/Docker/terraform/スクラム開発本は一旦買うのをやめることにした。Datadogに関する書籍は見つからなかった。
1/3 13:30-13:40(10分) 何をすれば良いか考える
1/3 13:30-15:50(2時間20分) SRE実践編の目次確認リスト化し、どの章を読むか（どの章を読まないか）決める
1/3 15:50-16:55(1時間5分) 2章 SLO の実装
1/3 16:55-17:30(35分) 4章 モニタリング
1/3 17:30-18:36(1時間3分) 5章 SLO に基づくアラート
1/3 18:36-19:03(27分) 11章 負荷の管理
1/3 19:03-19:41(38分) 12章 非抽象的な大規模システム設計の紹介
1/3 19:42-20:08(26分) 13章 データ処理パイプライン
1/3 20:08-20:23(15分) 14章 設定の設計とベストプラクティス
1/3 20:23-20:32(9分) 16章 カナリアリリース
1/3 20:32-20:40(8分) 18章 SRE のエンゲージメントモデル
1/3 20:40-20:41(1分) 19章 SRE: 壁の向こうへの到達
1/3 20:41-20:52(11分) 20章 SRE チームのライフサイクル

## やること

- 何をすれば良いか考える
  - できることをやる
    - SRE実践本の中の特定の章の読み込み
      - SRE実践編の目次確認リスト化し、どの章を読むか（どの章を読まないか）決める
        - 面談で与えられた期待されてる役割に直結する有益な情報が書かれている章
        - 常識レベルで重要度が高い情報が書かれている章（かつ読んだ方が良い）、弱点克服、自己啓発したい（肌感覚で気になる情報が書かれている）テーマに関する章
      - ひたすら読む
    - SRE実践本を読んだあとの行動をイメージする
      - 2月の案件で期待されてる役割に関連する実務知識のインプット
        - 面談で与えられた情報
            - Terraform
                - バージョン
                - 文法
                - 過去に実績のあるAWSサービスとコードの点検
            - Docker on EC2
                - 構成の特徴・よくある課題の確認
                - 最新のOS（EC2）で構成する場合のサーバ内アーキテクチャ
                - 実践に必要な操作・プロセス
            - IAMロール・ポリシーの最適化
                - 利用AWSサービスごとのIAMポリシー
                - 作成済みポリシー
                - IAMロール・ポリシーの分割単位のよくあるパターンを調べておく
            - MAU8000万の規模感で今後必要となりうるアクションをイメージしてそれに対応する準備
            - Python(大多数、読み書き), Go(読み書き)
            - ドキュメンテーションなくても大丈夫か？という確認（成熟期マトリクスを混乱期、機能、継続的改善の３つに分けた場合、混乱期の可能性が高い）
            - Datadogでのモニタリング実践

## やったこと

### SRE実践編の目次確認リスト化

```
1章 SRE と DevOps との関係
1.1 DevOps の背景
1.1.1 サイロの抑制
1.1.2 アクシデントは普通のこと
1.1.3 変化は徐々に起こすべきもの
1.1.4 ツールと文化は相互に関係する
1.1.5 計測は必須
1.2 SRE の背景
1.2.1 運用はソフトウェアの問題
1.2.2 サービスレベル目標 (SLO)による管理
1.2.3 トイルの最小化のための作業
1.2.4 今年のジョブの自動化
1.2.5 失敗のコストの削減による速度の向上
1.2.6 開発者との共有オーナーシップ
1.2.7 役割や仕事の肩書きに関わらず同じツールを使うこと
1.3 比較と対照
1.4 組織のコンテキストと成功する採用の促進
1.4.1 狭く硬直したインセンティブは成功を狭める
1.4.2 修正は自分で行う。 他の誰かを責めない.
1.4.3 信頼性に関する作業を特化した役割として考える
1.4.4 「やるかどうか」は「いつやるか」に置き換えられる.
1.4.5 評価の同等性のための努力:キャリアと金銭.
1.5 まとめ.

第1部 基礎

2章 SLO の実装
2.1 SRE に SLO が必要な理由 ..
2.2 始めてみよう
2.2.1 信頼性のターゲットとエラーバジェット
2.2.2 何を計測するか: SLI の利用.
2.3 うまく行った例.
2.3.1 SLI の仕様から SLI の実装への移行..
2.3.2 SLI の計測。
2.3.3 SLI を使った最初のSLO の計算
2.4 適切な時間ウィンドウの選択

2.5 ステークホルダーの同意を得る
2.5.1 エラーバジェットポリシーの確立
2.5.2 SLOとエラーバジェットポリシーのドキュメント化
2.5.3 ダッシュボードとレポート
2.6 SLO ターゲットの継続的改善
2.6.1 SLO の品質の改善
2.7 SLO とエラーバジェットを使った意思決定
2.8 高度なトピック
2.8.1 ユーザージャーニーのモデリング
2.8.2 インタラクションの重要性の段階付け.
2.8.3 依存関係のモデル化
2.8.4 SLO を緩めてみる
2.9 まとめ,

3章 SLO エンジニアリングのケーススタディ
3.1 Evernote における SLOの物語
3.1.1 Evernote が SRE モデルを採用した理由
3.1.2 SLO の導入 進行中の旅路
3.1.3 顧客とクラウドプロバイダーの間にあるSLOの壁を壊す 
3.1.4 現状、
3.2 Home Depot の SLO の物語
3.2.1 SLO 文化プロジェクト
3.2.2 最初のSLO群
3.2.3 SLOの普及
3.2.4 VALET データ収集の自動化
3.2.5 SLO の急増
3.2.6 バッチアプリケーションへの VALET の適用
3.2.7 テストでの VALET の利用
3.2.8 将来的な野望
3.2.9 まとめ..
3.3 結論

4章 モニタリング
4.1 モニタリング戦略における望ましい機能
4.1.1 速度.
4.1.2 計算
4.1.3 インターフェース
4.1.4 アラート
4.2 モニタリングデータのソース
4.2.1 例.
4.3 モニタリングシステムの管理
4.3.1 設定をコードとして扱う
4.3.2 一貫性の推進
4.3.3 疎結合の優先.
4.4 目的を持ったメトリクス
4.4.1 意図された変更
4.4.2 依存性.
4.4.3 飽和
4.4.4 ユーザートラフィックの状態
4.4.5 目的を持ったメトリクスの実装
4.5 アラートのロジックのテスト
4.6 まとめ

5章 SLO に基づくアラート....
5.1アラートについて考慮すべきこと...
5.2 重大なイベントに対するアラートの方法.
5.2.1 1:ターゲットのエラーレート SLOの閾値..
5.2.2  より長いアラートウィンドウ...
5.2.3 3:アラートの期間のインクリメント
5.2.4 4: バーンレートに対するアラート.
5.2.5 5: 複数バーンレートのアラート
5.2.6 6 複数ウィンドウ、 複数バーンレートのアラート....
5.3 低トラフィックのサービスとエラーバジェットによるアラー
5.3.1 人工的なトラフィックの生成
5.3.2 サービスの組み合わせ.
5.3.3 サービスとインフラストラクチャに対する変更の実施
5.3.4 SLO の引き下げあるいはウィンドウの拡大
5.4 極端な可用性のゴール
5.5 大規模環境におけるアラート...
5.6 まとめ

6章 トイルの撲滅
6.1 トイルとは何か?
6.2 トイルの計測。
6.3 トイルの分類学.
6.3.1 ビジネスプロセス
6.3.2 プロダクションへの割り込み..
6.3.3 リリースの世話.
6.3.4 マイグレーション
6.3.5 コストエンジニアリングとキャパシティプランニング
6.3.6 不明瞭なアーキテクチャのトラブルシューティング
6.4 トイル管理の戦略
6.4.1 トイルの特定と計測
6.4.2 システムから発生するトイルに対するエンジニアリング
6.4.3 トイルの拒否
6.4.4 SLO を使ったトイルの削減
6.4.5 人が背後に控えるインターフェースから始める
6.4.6 セルフサービスメソッドの提供
6.4.7 上司及び同僚から支援を得る
6.4.8 トイルの削減を機能に格上げする
6.4.9 小さく始めて改善する
6.4.10 一様性の増加
6.4.11 自動化に内在するリスクの評価
6.4.12 トイルへのレスポンスの自動化
6.4.13 オープンソース及びサードパーティツールの利用
6.4.14 改善のためのフィードバックの利用

6.5 ケーススタディ
6.6 ケーススタディ 1 自動化によるデータセンター内のトイルの削減
6.6.1 背景
6.6.2 問題の内容
6.6.3 実行すると決めたこと
6.6.4 最初の活動の設計: Saturn ラインカードの修理
6.6.5 実装.
6.6.6 2番目の活動の設計: Saturn ラインカードの修理対Jupiter ラインカードの修理
6.6.7 実装
6.6.8 学んだこと
6.7 ケーススタディ 2: ファイラーを背後に持つホームディレクトリの廃止 背景
6.7.1 背景
6.7.2 問題の内容
6.7.3 実行すると決めたこと....
6.7.4 設計と実装。
6.7.5 主要なコンポーネント
6.7.6 学んだこと....
6.8 まとめ

7章 単純さ
7.1 複雑さの計測
7.2 単純さはあらゆる場面で目指すべきことであり、SRE はその追求に適している
7.2.1 ケーススタディ1:エンドツーエンドのAPI の単純さ
7.2.2 ケーススタディ2:プロジェクトのライフサイクルの複雑さ
7.3 単純さの再獲得
7.3.1 ケーススタディ 3 : Display Ads Spiderweb の単純化
7.3.2 ケーススタディ 4:共有プラットフォーム上での数百の マイクロサービスの実行.
7.3.3 ケーススタディ 5:pDNSはもう自分自身に依存しない
7.4 まとめ

第II部 実践

8章 オンコール
8.1「オンコール対応」の章の振り返り「SRE サイトリライアビリティエンジニアリング』の
8.2 Google 内外でのオンコールの構成例
8.2.1 Google: 新しいチームの形成
8.2.2 Evernote: クラウドへの順応
8.3 実用的な実装の詳細
8.3.1 ページャーの負荷の解剖学
8.3.2 オンコールの柔軟性
8.3.3 オンコールチームの力学.
8.4 まとめ

9章 インシデント対応
9.1 Google におけるインシデント管理.
9.1.1 インシデントコマンドシステム
9.1.2 インシデント対応における主な役割
9.2 ケーススタディ
9.2.1 ケーススタディ 1: ソフトウェアのバグ-ライトはついているのに誰も (Google の)ホームにいない
9.2.2 ケーススタディ2:サービスの障害できるものなら捕まえて
9.2.3 ケーススタディ 3:電源喪失 雷に2回打たれるなどという
ことは起こらない・・・・・・それが起こるまでは
9.2.4 ケーススタディ 4: Pager Duty におけるインシデント対応
9.3 ベストプラクティスの実践 
9.3.1 インシデント対応のトレーニング
9.3.2 事前準備
9.3.3 練習
9.4 まとめ

10章 ボストモーテムの文化: 失敗からの学び、
10.1 ケーススタディ
10.2 良くないポストモーテム
10.2.1 このポストモーテムが良くない理由
10.3 良いポストモーテム
10.3.1 このボストモーテムが良い理由
10.4 組織的なインセンティブ、
10.4.1 非難のない振る舞いのモデル化と実施
10.4.2 ボストモーテムの成果に対する報酬
10.4.3 ボストモーテムのオープンな共有
10.4.4 ボストモーテム文化の失敗への対応.
10.5 ツールとテンプレート
10.5.1 ポストモーテムのテンプレート
10.5.2 ポストモーテムのツール
10.6 まとめ

11章 負荷の管理
11.1 Google Cloudのロードバランシング
11.1.1 anycast
11.1.2 Maglev
11.1.3 Global Software Load Balancer..
11.1.4 Google Front End
11.1.5 GCLB 低レイテンシー
11.1.6 GCLB: 高可用性
11.1.7 ケーススタディ 1: GCLB 上での Pokémon GO
11.2 オートスケーリング
11.2.1 不健全なマシンの処理.
11.2.2 ステートフルなシステムの扱い
11.2.3 保守的な設定
11.2.4 設定の制約
11.2.5 キルスイッチと手動オーバーライドの取り込み
11.2.6 バックエンドの過負荷の回避
11.27 トラフィックの不均衡の回避
11.3 負荷の管理のための戦略を組み合わせる
11.3.1 ケーススタディ 2:ロードシェディングが自らの首を絞める
11.4 まとめ

12章 非抽象的な大規模システム設計の紹介
12.1 NALSD とは何か?
12.2 なぜ「非抽象的」なのか?
12.3 AdWords の例
12.3.1 設計プロセス
12.3.2 初期の要件
12.3.3 1台のマシン
12.3.4 分散システム
12.4 まとめ

13章 データ処理パイプライン
13.1 パイプラインアプリケーション
13.1.1 データの並び替えあるいは構造化のための イベント処理 / データ変換
13.1.2 データ分析
13.1.3 機械学習
13.2 パイプラインのベストプラクティス
13.2.1 サービスレベル目標の定義と計測
13.2.2 依存性障害のための計画
13.2.3 パイプラインのドキュメンテーションの作成と管理
13.2.4 開発ライフサイクルのマッピング
13.2.5 ホットスポットの低減とワークロードパターン
13.2.6 オートスケーリングの実装とリソース計画
13.2.7 アクセス制御とセキュリティポリシーの遵守
13.2.8 プランのエスカレーションパス
13.3 パイプラインの要求と設計
13.3.1 必要な機能は?
13.3.2 冪等と2フェーズの変換
13.3.3 チェックポイント処理
13.3.4 コードのパターン
13.3.5 パイプラインのプロダクションレディネス
13.4 パイプラインの障害: 回避と対応
13.4.1 潜在的な障害の形態
13.4.2 潜在的な原因
13.5 ケーススタディ : Spotify
13.5.1 イベント配信.

13.5.2 イベント配信システムの設計とアーキテクチャ
13.5.3 イベント配信システムの運用..
13.5.4 顧客の統合とサポート
13.5.5 まとめ
13.6 結論,

14章 設定の設計とベストプラクティス
14.1 設定とは何か?
14.1.1 設定と信頼性、
14.1.2 哲学と仕組みの分離
14.2 設定の哲学
14.2.1 ユーザーに質問する設定.
14.2.2 質問はユーザーの目標に近いものであるべき
14.2.3 必須の質問とオプションの質問
14.2.4 単純さからの脱却
14.3 設定の仕組み
14.3.1 設定と結果データの分離
14.3.2 ツールの重要性
14.3.3 所有権と変更追跡
14.3.4 安全な設定変更の適用.
14.4 まとめ

15章 設定の詳細
15.1 設定が引き起こすトイル
15.2 設定が引き起こすトイルの削減
15.3 設定システムの重要な属性と落とし穴
15.3.1 落とし穴1: 設定をプログラミング言語の問題と認識しない
15.3.2 落とし穴 2: 偶然あるいはアドホックな言語機能の設計
15.3.3 落とし穴3: 過剰なドメイン固有の最適化
15.3.4 落とし穴4: 「設定の評価」 への 「副作用」の混入
15.3.5 落とし穴 5 : Python Ruby Lua のような既存の汎用スクリプティング言語の利用
15.4 設定言語の統合
15.4.1 特定のフォーマットでの設定の生成
15.4.2 複数のアプリケーションの駆動
15.5 既存のアプリケーションの統合: Kubernetes
15.5.1 Kubernetes が提供するもの。
15.5.2 Kubernetes の設定の例
15.5.3 設定音の統合。
15.6 カスタムアプリケーション(インハウスソフトウェア)の統合。
15.7 効果的な設定システムの運用
15.7.1 バージョニング、
15.7.2 ソース管理
15.7.3 ツール
15.7.4 テスト
15.8.1 非常に早い段階: JSONのチェックイン
15.8 いつ設定を評価するか、
15.8.2 途中の段階: ビルド時点での評価。
15.8.3 終盤: 実行時の評価
15.9 不正な設定に対するガード
15.10 まとめ

16章 カナリアリリース
16.1 リリースエンジニアリングの原則.
16.2 リリースの速度と信頼性のバランス
16.3 カナリアとはなにか?
16.4 リリースエンジニアリングとカナリア
16.4.1 カナリアプロセスの要求
16.4.2 サンプルのセットアップ.
16.5 ロールフォワードデプロイメント対シンプルなカナリアデプロイメント
16.6 カナリアの実装
16.6.1 SLOとエラーバジェットに対するリスクの最小化
16.6.2 カナリアの対象数と期間の選択
16.7 メトリクスの選択と評価。
16.7.1 メトリクスは問題を示すものであるべき
16.7.2 メトリクスは代表的で起因を示すものであるべき
16.7.3 事前事後の評価はリスクを含む....
16.7.4 より優れたメトリクス選択のための段階的なカナリアの利用
16.8 依存関係と隔離
16.9 非インタラクティブなシステムでのカナリア
16.10 モニタリングデータに対する要求
16.11 関連する概念
16.11.1 ブルー/グリーンデプロイメント
16.11.2 人工的な負荷生成
16.11.3 トラフィックティーイング
16.12 まとめ..

第III部 プロセス
17章 過負荷の特定と回復
17.1 負荷から過負荷へ
17.2 ケーススタディ1:チームの半分が去った時点での作業過負荷 ケースス
17.2.1 背景、
17.2.2 問題の表明
17.2.3 実行すると決めたこと...
17.2.4 実装
17.2.5 学んだこと.
17.3 ケーススタディ 2: 組織及び作業負荷の変更後の認知過負荷 17.3.1 背景.
17.3.2 問題の表明
17.3.3 実行すると決めたこと
17.3.4 実施
17.3.5 効果
17.3.6 学んだこと
17.4 過負荷の緩和のための戦略
17.4.1 過負荷の症状の認識
17.4.2 過負荷の低減とチームの健全性の回復
17.5 まとめ

18章 SRE のエンゲージメントモデル
18.1 サービスのライフサイクル
18.1.1 フェーズ1: アーキテクチャと設計
18.1.2 フェーズ 2: 活発な開発.
18.1.3 フェーズ3: 限定公開
18.1.4 フェーズ 4:一般公開 (GA)
18.1.5 フェーズ5 非推奨化
18.1.6 フェーズ6: 放棄
18.1.7 フェーズ7: サポート終了
18.2 関係性のセットアップ
18.2.1ビジネスとプロダクションの優先順位のコミュニケーション
18.2.2 リスクの特定
18.2.3 目標を揃える
18.2.4 基本原則の設定
18.2.5 計画と実行
18.3 効率的な継続的関係性の維持
18.3.1 よりうまく共同で働けるようになることへの時間の投資。
18.3.2 オーブンなコミュニケーション経路の維持
18.3.3 定期的なサービスレビューの実施
18.3.4 基本原則がずれ始めた時点での再評価。
18.3.5 SLO とエラーバジェットに基づく優先順位の調整.
18.3.6 適切なミスの処理
18.4 より大規模な環境へのSRE のスケール
18.4.1 単一のSRE チームでの複数サービスのサポート
18.4.2 複数の SRE チーム環境の構造化.
18.4.3 変化する環境への SRE チームの構造の適応
18.4.4 まとまりのある分散 SRE チームの運営
18.5 関係性の終了
18.5.1 ケーススタディ 1: Ares.
18.5.2 ケーススタディ2:データ分析パイプライン..
18.6 まとめ

19章 SRE: 壁の向こうへの到達
19.1 我々が自明だと考える真実
19.1.1 信頼性は最も重要な機能
19.1.2 モニタリングではなくユーザーが信頼性を決める
19.1.3 プラットフォームを動作させるなら、信頼性はパートナーシップである
19.1.4 重要なものはすべていつかプラットフォーム化する
19.1.5 顧客が苦労しているなら 速度を落とさなければならない。
19.1.6 SRE は顧客と共に実践しなければならなくなる
19.2 ハウツー:顧客とのSRE
19.2.1 ステップ 1: SLO と SLI が会話の手段
19.2.2 ステップ2:モニタリングの監査と共有ダッシュボードの構築
19.2.3 ステップ 3: 計測と再交渉
19.2.4 ステップ 4: 設計レビューとリスク分析
19.2.5 ステップ 5: 実践、 実践、 実践
19.2.6 思慮深く規律を守る
19.3 まとめ

20章 SRE チームのライフサイクル
20.1 SRE なしでのSRE の実践
20.2 SRE ロールの開始
20.2.1 最初のSRE を見つける
20.2.2 最初のSRE の配置
20.2.3 最初のSRE の立ち上げ
20.2.4 分散 SRE
20.3 最初のSRE チーム
20.3.1 形成期
20.3.2 混乱期.
20.3.3 統一期.
20.3.4 機能期
20.4さらなるSRE チームの形成
20.4.1 サービスの複雑さ
20.4.2 SRE の展開
20.4.3 地理的な分割
20.5 多数のチームの運営のための推奨プラクティス
20.5.1 ミッションコントロール
20.5.2 SRE Exchange.
20.5.3 トレーニング
20.5.4 横断的プロジェクト
20.5.5 SRE の流動性
20.5.6 出張
20.5.7 ローンチ調整エンジニアリングチーム
20.5.8 プロダクションエクセレンス
20.5.9 SRE への投資と雇用.
20.6 まとめ

21章 SRE における IT 変更管理.
21.1 SRE は変化を抱擁する
21.2 変更管理の紹介
21.2.1 Lewin の3ステージモデル
21.2.2 マッキンゼーの7Sモデル
21.2.3 Kotter の変更をリードするための8ステッププロセス
21.2.4 Prosci の ADKAR モデル
21.2.5 感情ベースのモデル
21.2.6 デミングのサイクル
21.2.7 これらの理論のSREへの適用
21.3 ケーススタディ 1: Waze のスケーリング アドホックな変更から計画された変更へ,
21.3.1 背景
21.3.2 メッセージキュー:信頼性をメンテナンスしながらのシステムの置き換え
21.3.3 変更の次のサイクル:デプロイメントプロセスの改善。
21.3.4 学んだこと
21.4 ケーススタディ 2: SRE における共通ツールの採用。
21.4.1 背景.
21.4.2 問題の状況
21.4.3 実行すると決めたこと
21.4.4 設計.
21.4.5 実装:モニタリング
21.4.6 学んだこと

21.5 まとめ
この先.......
将来は過去に属する
SRE + <他の分野>
しずく、細流、そして奔流
SRE は私たち全員のもの
謝意
付録A SLO ドキュメントの例.
付録B エラーバジェットポリシーの例
付録C ポストモーテム分析の結果
```

### どの章を読むか（どの章を読まないか）決める

- 読む
  - [x] 2章 SLO の実装 より重要なサービスの信頼性改善にエンジニアリングリソースを投下する / 成熟レベル（新規開発、プロダクション運用中・エラーバジェットの概念はない・１００％稼働という暗黙の目標、１００％を下回るSLOが設定されているが、どう活用するかの共通理解は欠けている）, 意思決定と優先順位づけにエラーバジェットを利用する組織内コンセンサス、SLO改訂プロセス、信頼性のターゲット（顧客を満足している状態に保つために信頼性を保つ、可用性、９９％、９９.９％、９９.９９％）、SLI（何を計測するか、リクエスト成功率）、エラーバジェットとは？1ヶ月300万リクエスト受信するサービス、SLOがリクエスト成功率９９.９％の場合、1ヶ月のエラーバジェットは３０００。1回の障害で１５００のエラーが発生したらエラーバジェットの５０％を消費したことになる, SLIの種類（可用性、レイテンシー、品質、新鮮さ、正確性、カバレッジ、耐久性）, 4週間のローリングウィンドウ。エラーバジェットポリシー（エラーバジェットを使い果たした＝SLOが満たされなかった時に何を行うかを決めたもの）, ダッシュボード・レポート, エラーバジェットポリシーのドキュメント: ポリシー作成者・承認者、作成・承認日付、次のレビュー日程、バジェットを使い果たした時に行うアクション、計算結果あるいは同意済みアクションの妥当性に関する異議が発生した場合のエスカレーションパス, SLOのドキュメント: SLO作成者・承認者、作成・承認日付、サービス概要、目標SLO,SLI実装,エラーバジェットの計算・消費仕様, SLOターゲットの継続的改善に使えるユーザ満足度評価の情報源(サービス障害、サポートチケット、カスタマーサービスへの電話数、SNSのユーザ感情計測、満足度を定期的にサンプリングするコード、カスタマーサーベイ)
  - [x] 4章 モニタリング（メトリクスと構造化ロギング, データ取得速度要求、計算。単調増加するカウンターによるイベントやリソース消費量のデータ保持が理想。少なくとも数ヶ月のデータを保持。統計関数をサポートしているモニタリングシステムの有益性。パーセンタイルをサポートしたモニタリングシステム、算術平均から得られるのは, 一貫性の推進、モニタリングシステムのコンポーネント同士の疎結合の優先（データ収集、保存、アラート、可視化の４つのコンポーネント）SLPベースのアラート診断（バイナリバージョン、コマンドラインフラグのモニタリング、設定データのバージョンモニタリング）、飽和（goroutine数）、リソースが絶対的な制限に達する場合、閾値を超えることでパフォーマンス低下が生じる場合、目的を持ったメトリクスの実装・ポストモーテムを書く時どんなメトリクスがあれば問題の診断を早く行えたかを考える。アラートのロジックのテスト。合成時系列データを作成できるドメイン固有言語を使ってモニタリングのテスト
  - [x] 5章 SLO に基づくアラート アラートの戦略を評価するTOKINI考慮すべきこと４つ（適合率（precision）・再現率（recall）、検出時間（事象が発生してから通知が送られるまでの時間。エラー検出タイムラグのこと）・リセット時間（問題解決したあとアラートが発生し続けた時間の長さ＝アラートがリセットされるまでのタイムラグのこと）。ターゲットのエラーレート＞＝SLO閾値を実装するPrometheusレコーディングルール（例えば、alert: HighErrorRate, expr: job:slo_errors_per_request:ratio_rate10m{job="myjob"} >= 0.001)）。大規模環境におけるアラート。リクエストのグループ化。CRITICAL, HIGH_FAST,HIGH_SLOW,LOW,NO_SLO
    - 30日間のエラーバジェットの５％が1時間で消費されるために必要なバーンレートは３６。分母がSLOのローリングウィンドウ（単位：時間）、分子はエラーバジェットの１００％を消費するまでにかかる時間
      - バーンレート
        - 優れた検出時間と高い適合率を持つアラートを作成したいなら、バーンレートに基づくアラートを作成すると良いらしい。
          - バーンレートを導入すると、ウィンドウサイズを小さくしながらアラートによるバジェットの消費を一定に保てる
            - バーンレートを導入すると、優れた検出時間と高い適合率を持つアラートを作成できる?ってことでいいの？
              - ウィンドウサイズを小さくする＝優れた検出時間
              - バジェットの消費を一定に＝高い適合率＝全てのアラートがSLO上の重要性に適した通知になっている
          - バーンレートとはSLOに対して相対的にサービスがどれだけの速度でエラーバジェットを消費するか
        - ３０日間のエラーバジェットの５％が1時間で消費されることのアラート検出をしたい場合のバーンレートは３６
          - 低い再現性の短所の説明でバーンレート３５が引き合いに出されているのはなぜ？
          - 長所・短所に記載されてる５８分というリセット時間はどこからきた？
          - バーンレートの計算式に使われてる0.001は何の数字？99.999%
  - [x] 11章 負荷の管理a (SREサイトリライアビrティエンジニアリングの１９章フロントエンドにおけるロードバランシングに目を通すのが推奨されてる。２０章データセンターロードバランシングの哲学も目を通す)。MaglevというGoogleのカスタム分散バケットレベルロードバランサはAWSにも存在する？安定化anycast。コンシステントハッシング、接続追跡（コネクショントレース）GFE/Google Front Ends = HTTPリバースプロキシ。GCLBは可用性９９、９９％SLA、不健全なマシンの処理、負荷の管理のために戦略を組合せる（オートスケーリング＝AWS AutoScaling、ロードバランシング=ALB/NLB/Nginx/HAProxy、負荷制限(ロードシェディング)=Envoy/Zuul）
  - [x] 12章 非抽象的な大規模システム設計の紹介 (NALSD=Non-Abstract Large Scale System Design大規模なシステムを査定し設計し評価する能力を表す。SREにとって必要な能力を表す。キャパシティプランニング、コンポーネントの分離、システムのグレースフルグラデーション。基本的な設計フェーズでは実現可能か、もっと上手いやり方はないかの２つの質問を発せられる。次にスケールアップに取り組む。現実的か＝与えられた資金・ハードウェア上の制約でスケールさせることは可能？、弾力性があるか＝障害が起こったら何が起きるか。SREがシステム設計のキーとなる側面んを分析し評価できることが極めて重要。このコンポーネントに障害が起きたら何が起きるかという質問に対してテストしていくと単一障害点のリストが出来上がる。ネットワークスループット（bps）、ログサイズ（TB)、入出力シャーディング。合意アルゴリズム。分散合意アルゴリズム。)抽象的な要求から具体的なリソースを推定し求めることがシステム構築するものにとって欠かせない能力
  - [x] 13章 データ処理パイプライン この章では、一般的なビッグデータの処理パイプラインの検証をやってる。パイプラインの健全性を保つための信頼性指標を考える役割を担うSREにとって必要な検証プロセスなのか？MLデータパイプラインとは。データセットから特徴・ラベルを抽出ー＞抽出した特徴でモデルをトレーニング→テストセットでモデルを評価→他のサービスからモデルを使えるようにする→モデルかr返された反応を利用して他のシステムが判断を下す。ETLパイプライン。複数データソースにまたがるデータフォーマットの変更、集計演算、データを利用するジョブに役立つ優れた特性を持たせるためデータにインデクスを適用する。開発ライフサイクル（プロトタイプ→1％Dry-run→ステージング→カナリア→部分的デプロイ→プロダクション。レイテンシー・データの正確性・高可用性・MTTR＝インシデントの平均解消時間・MTTD＝平均障害検出時間、エラーがプロダクションに到達するのを避ける開発ライフサイクル、リソースの利用あるいはコストの調査と予測、開発の用意さ、運用の容易さ、冪等な変更デザインパターン＝２フェーズの変換デザインパターン＝１つ目のフェーズで計画された変更を中間データソースに保管。中間データソースを検証後に、２つ目のパイプラインで変更を適用。パイプライン成熟マトリクス。システムの信頼性を高めるような設計上の選択、利用可能な技術の評価、設計と一般的なタスクの実行方法をドキュメント化）
  - [x] 14章 設定の設計とベストプラクティス 初期設定と、インシデント対応のための緊急時の再設定。３つのコンポーネント（ソフトウェア、データセット、システムの設定の３つ）。Jsonnet。Kubernetes yamlへのコンパイルに使われている設定と結果データの分離の仕組み。現実世界における類例。セマンティクス検証(linter, syntax-formatter), 所有権と変更追跡, 安全な設定変更適用（all or nothingではなく徐々にデプロイできる、危険だと分かった場合ロールバックできる、運用者の制御が失われることにつながる場合自動的にロールバックされる。システム管理者が設定していう最中のシステムからファイアーウォールで切断されてしまうケース、デスクトップシステムの場合画面の解像度の変更の際はカウントダウンが表示され、ユーザが変更を確認しなければリセットされることがよくある）。カナリア分析サービスACM Queueの記事を参照。
  - [x] 16章 カナリアリリース リリースエンジニアリングの原則、カナリアプロセス。サービスの変更を部分的かつ時間的制限をした上でデプロイ・評価を行うことと定義されている。ユニットテストや負荷テストのテストフレームワークでは見えてこない問題を特定できることもある。ブルーグリーンデプロイ・人工的な負荷生成・トラフィックティーイング（トラフィックのコピーをテスト環境にも転送することで更なる分析行う）
  - [ ] 18章 SRE のエンゲージメントモデル（目標を揃える、信頼性・可用性・パフォーマンス・スケーラビリティ・効率性・機能のローンチ速度。開発チームのリリース速度を支援し、認可されたすべてのローンチを成功させるという明示的な目標、進行中のサービスの問題に対する設計・実装レベルの問題解決、技術的負債解消、新機能の開発の早期段階にSREとして関わる、設計の議論にも参加する）一般公開（GA)NOフェーズ内でのSREとしての取り組み。スプリントコミュニケーション(P386), 基本原則の設定(短期的目標=可用性・要求に応じてスケールするシステム、メンテナンス性、ビジネス要求を満たす, 長期的目標＝高付加価値のエンゲージメントの仕事に移行できるようにする)。関係性の終了
  - [x] 19章 SRE: 壁の向こうへの到達 SLOとSLIが会話の手段、モニタリングの監査と共有ダッシュボード構築。計測と再交渉（計測内容を決めたら1ヶ月、2ヶ月にわたって収集）、信頼を構築しMTTRを引き下げる。顧客数が多い場合、全顧客に会話の手段を適用しようとせず、収入・機能・作業負荷のカバレッジを活用して、最小限の数の顧客に限定し効率的に取り組むように心がける。
  - [x] 20章 SRE チームのライフサイクル(問題が出た時にシステムを理解しやすくするためのモニタリング改善、過去のポストもーテムで挙げられた優先度高のアクションに着手、トイ流撲滅のための自動化)、Tuckmanのパフォーマンスモデルと形成期、混乱期、統一期、機能期という段階（形成期：問題の検出と緩和を促進するソフトウェア、自動化するソフトウェア）、信頼性とパフォーマンス改善のためのソフトウェア、メンテナンス性を改善するため、システムアーキテクチャを理解する）、統一期は
- 読まない（積極的には読まない。暇があれば適当に目を通す）
  - 1章 SRE と DevOps との関係
  - 3章 SLO エンジニアリングのケーススタディ
  - 6章 トイルの撲滅
  - 7章 単純さ
    - 読んだ方がいい? 7.1 複雑さの計測, 7.2.1 ケーススタディ1:エンドツーエンドのAPI の単純さ, 7.2.2 ケーススタディ2:プロジェクトのライフサイクルの複雑さ
  - 8章 オンコール
  - 9章 インシデント対応
  - 10章 ボストモーテムの文化: 失敗からの学び、
  - 15章 設定の詳細
  - 17章 過負荷の特定と回復
  - 21章 SRE における IT 変更管理.

## 次のアクション

- チームのライフサイクルを再確認し、立ち上げ・混乱・統一・機能４つのフェーズに対する自分の立ち回りをもう１段階具体的にイメージする

- 現実世界における類例を、面談の情報をもとに掘り下げていく
  - ライフサイクルの現在位置、形成期・関係性の終了
    - Terraform
        - バージョン
        - 文法
        - 過去に実績のあるAWSサービスとコードの点検
    - Docker on EC2
        - 構成の特徴・よくある課題の確認
        - 最新のOS（EC2）で構成する場合のサーバ内アーキテクチャ
        - 実践に必要な操作・プロセス
    - IAMロール・ポリシーの最適化
        - 利用AWSサービスごとのIAMポリシー
        - 作成済みポリシー
        - IAMロール・ポリシーの分割単位のよくあるパターンを調べておく
    - MAU8000万の規模感で今後必要となりうるアクションをイメージしてそれに対応する準備
    - Python(大多数、読み書き), Go(読み書き)
    - ドキュメンテーションなくても大丈夫か？という確認（成熟期マトリクスを混乱期、機能、継続的改善の３つに分けた場合、混乱期の可能性が高い）
    - Datadogでのモニタリング実践

- 上記以外で、SREの実践本の読み直すポイントと計画を再検討する。
